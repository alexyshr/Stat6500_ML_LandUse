---
output: 
  bookdown::pdf_document2:
    toc: False
    extra_dependencies: ["float"]
header-includes:
- \usepackage{fancyhdr}
- \usepackage{lastpage}
- \usepackage{amsmath}
- \usepackage{tocloft}
- \usepackage{placeins}
- \usepackage{float}
bibliography: ref.bib
link-citations: yes
always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
#knitr::opts_chunk$set(fig.pos = "!H", out.extra = "")
library(reticulate)
library(GGally)
library(dplyr)
library(bookdown)
library(GGally)
library(corrplot)
library(knitr)
library(kableExtra)
library(formattable)
```


```{python include=FALSE}
import numpy as np
import pandas as pd
import seaborn as sns
sns.set_style('whitegrid')
import matplotlib.pyplot as plt
import os
import time
from plotly import tools
from plotly.offline import plot
import plotly.offline as py
from plotly.graph_objs import Scatter, Layout
import plotly.graph_objs as go
import plotly.figure_factory as ff
```


\fancyfoot[C]{\thepage\ of \pageref{LastPage}}

\newpage
\begin{titlepage}
\begin{center}
\vspace*{1cm}
\large{STAT 6500}\\
\vspace*{2cm}
\line(1,0){400}\\
\huge{\textbf{Statistical Machine Learning}}\\
\vspace*{1cm}
Land Use Cover\\
\vspace*{1cm}
\normalsize{\textbf{Kendall Byrd - Atitarn Dechasuravanit - Alexys Rodriguez - Abdulaziz Alsugair}}\\

\vspace*{1cm}
\normalsize{Final Report}\\

\line(1,0){400}
\vfill
\huge{Spring 2022}\\
Monday, May 2
\end{center}
\end{titlepage}


\newpage
\tableofcontents
 

\newpage
\pagestyle{fancy}
\fancyhead[L]{\slshape Land Use Cover}
\fancyhead[C]{\slshape STAT 6500}
\fancyhead[R]{\slshape Final Report}

# Introduction

For this study, we propose implementing machine learning techniques on image segmented super-objects, to determine the effect scale has on accurately classifying land cover maps using super-object's features, extracted from urban satellite imagery at multiple image segmentation scales. The data set that will be analyzed in this project is the Urban Land Cover Data Set, see @urbanlandcover. This data can be found in the UCI Machine Learning Repository and it was originally sourced by [@Johnson2012; @Johnson2013].

## Original Project Description

The authors of the original project, @Johnson2013, classified a high'resolution image of an urban area using super-object information, i.e. the objects in the images (groups of pixels), representing real objects in the field (buildings, trees, cars, etc.) that a specific pixel belongs to. To extract those super-objects an image segmentation method to generate vectors (polygons) representing the real objects was used. The mentioned algorithm mainly depends of the input parameter *image pixel scale*, which represents the scale of the image used, relative to the original pixel size. Single pixels or fine-scale image segments, for instance in Figure \@ref(fig:imagesegmentation), scale 20% left image (a), can generate multiple segments (polygons) for each super-object, and on the other side, a coarser scale, right image (c) at 140%, can mix multiple super-objects into one image segment. Depending on the real size of the original super-object, there is an optimum extraction scale, center image (b) at 80%. @Johnson2013 extracted the super-object for the multiple image segmentation scales, i.e. 20%, 40%, 60%, 80%, 100%, 120%, and 140%, and for each one, assigned **spectral** (vegetation index NDVI, average objects reflectance for each spectral band, etc.), **texture** (contrast, correlation, energy or homogeneity from the Gray-level co-occurrence matrix - GLCM), **size** (area, length, others) and **shape** (roundness, shape index, etc.) features, with the purpose of measuring the contribution of coarseness scales (individually and together) in the land cover use classification of the image, using machine learning techniques. In @Johnson2012, the authors created the land cover map from the original image, taking advantage of the improvements in model accuracy due to the additional feature information at different image segmentation scales.



```{r imagesegmentation, echo=FALSE, fig.align="center", fig.cap="Image segmentation as a function of the pixel scale. Source: Johnson (2012)", message=FALSE, warning=FALSE, out.width = "50%"}
knitr::include_graphics("./in/image_segmentation-scale.png", dpi=NA)
```

\FloatBarrier


## Data Description

The multivariate Urban Land Cover data set has 168 rows and 148 columns. It has twenty-two attributes, that are repeated for seven different coarser scales. It contains training and testing data for classifying a high-resolution aerial image into nine classes (target classification variable) of urban land cover.  The nine land cover classes are *concrete*, *trees*, *soil*, *grass*, *buildings*, *cars*, *asphalt*, *pools*, and *shadows*. There are a low number of training samples for each class (14-30) and a high number of classification variables (148), so testing different feature selection methods will be interesting. The testing data set was generated from super-objects random sampling of the image. All attribute abbreviations and brief explanations can be seen in the Table \@ref(tab:table1).


```{r table1, echo=FALSE}
df = read.csv("./data/variable_description.csv", header=FALSE)
knitr::kable(df, caption = "Variables Description",
             col.names = c("Variables", 
                           "Variables")) %>%
      column_spec(1,width = "2in") %>%
      column_spec(2,width = "3.8in") %>%
kable_styling(font_size = 8, latex_options="hold_position")
```


\FloatBarrier

Table \@ref(tab:cs) describes the features set for different coarser scales.


```{r cs, echo=FALSE}
df = read.csv("./data/feature_sets.csv")
knitr::kable(df, caption = "Feature Sets by Image Segmentation Scales", 
             col.names = c("Feature Set", "Scale", 
                           "Number of Variables", "Variables Names",
                           "Variables Suffix")) %>%
      #column_spec(1,width = "2in") %>%
      #column_spec(2,width = "3.8in") %>%
kable_styling(font_size = 8, latex_options="hold_position")
```

\FloatBarrier


## Project Objectives

The practical end-goal is:

1. To reduce the cost of the image segmentation post-process by selecting a single coarseness level (resolution) that produces most accurate prediction, in order to create land cover maps from urban satellite images, and using multiple super-object's feature information at different scales,

2. To optimize object identification by selecting the best classification method in terms of (a) model accuracy, (b) model simplicity, (c) operational cost and (d) model interpretability.

# Problem statement

Based on the study from [@Johnson2012; @@Johnson2013], urban land-cover information is essential for numerous urban-planning applications, for instance, green space analysis, @inbook, and urban land-use mapping, @article. Most land cover has traditionally been obtained from satellite images using pixel-based image classification techniques. Nevertheless, in fine spatial resolution images with spectral variability within the same class can lead to low accuracy for classification using pixel-based image classification techniques. Therefore, @Johnson2012 presented the object-based classification methods involving segmentation of the image on different scales. The average size of the segment will vary depending on the specified scale parameter. These scales were ranging from 40 to 140 with 20 intervals in this study. For each image segment, features such as spectral (mean values and variance for each band), mean normalized differential vegetation index (NDVI), area, shape, texture, length and so on were calculated in one of different scales (21 features for each scale). 

This project aims to use machine learning techniques and statistical tools that are different from the techniques used in the original study, to predict the target class of the object derived from segmentation at different scales of high-resolution urban-land cover image. Three machine learning techniques which are *neural networks*, *random forest* and *k-nearest neighbors* will be used for this project. The comparison of different classifiers for each scale and how well each classifier can perform at the different scales will be analyzed. In total, 24 machine learning models will be implemented in this study (seven scales with three machine learning techniques for each scale, plus the three methods applied to the whole data set) 


# Methods

Given mentioned objectives, the project team opted to perform concurrent analyses on the data where all proposed classification methods are used to classify objects across all coarseness levels; The combination of resolution and classification method that produces the most accurate predictions on the testing data will be selected as the one that meets the objectives.


## Available resolutions and variables

The data was already collected and presented at 7 coarseness levels, each having 21 variable. The data will be processing will include: (a) eliminating highly correlated variables resulting in 12 independent variables (only for neural networks and nearest neighbors), (b) nominalizing all values to be used in the Neural Networks model, (c) compare original transformed (standard scaling) variables,  (d) include machine learning models for independent feature sets (each feature set independently), (d) include machine learning models for all the variables (all feature sets integrated as a unit), and (e) analyze feature importance (random forest).

## Classification methods

The team will be attempting 3 different classification methods:

### Neural Networks

A supervised feed-forward neural networks model will be trained using the training data (168 points); and consists of 21 nodes in the input layer and 9 nodes in the output layer representing the available variables and the object classes. The team will attempt to optimize the models by varying the number of hidden layers and the number of nodes in each layer. The resultant models will be used to predict classes using the testing dataset to estimate each model's accuracy. For a overview, frameworks and challenges of Neural Networks see @Prieto2016.

### Random Forest

The random forest decision tree model is less computationally expensive to train and to implement, thus, serving the objective of reducing data collection and classification cost. The decision tree model is created by recursively branching the data using the variable that adds most to the prediction of model; from that branch further branching is made using the best variable (the same variable may be used again). The recursion process stops when no further branching adds to the prediction value (e.g. when splitting the data results in 50/50 odds). The random forest creates multiple decision trees, each with different and random branching, regardless of the predictive power. The prediction can be performed using voting schema (majority) or averaging the results. More information applications of random forest classifier in remote sensors can be found in @Belgiu2016.

### K-Nearest Neighbor

The simplest of models, where the class of an input is determined by its neighboring points. Either the euclidean or manhattan distance is used to determine the distance from other data points; and the class of the input point is predicted to be the same as the majority of its neighbors. The number of nearest neighbors can tuned to produce more accurate predictions. See @Taunk2019 for a clear review of this classifier for learning and classification purposes.

# Results

### Neural Networks
A total of 42 models were trained; 7 datasets (one for each coarseness level), 6 hidden layer configurations (1,2, or 3 layers; with 10 or 20 nodes per layer). The package 'neuralnet' was used train the models ('rprop+' algorithm; Logistic activation function; minimizing SSE as error function; stopping criteria: reaching 100,000 epochs or SSE difference of 0.01 from previous run). All 42 trained models were used to predict the test data (507 observations) from their corresponding dataset (i.e. training a model on data from coarseness level 80, and predicting the classes on testing data 80). The tests error rate, time to train, and number of epochs to reach a stopping criteria were recorded. The test error rate ranged from 28% - 46.7%; Compute time ranged from 0.37 - 1.64 seconds; and number of epochs ranged from 294 - 1917 steps. Originally, the team was planning to use compute time/epochs as decision criteria for selecting the best model, however, training time difference was only 1.27 seconds between best and worst models. Therefore, it was decided to consider test error rate solely in choosing the best model.  
The best model (the one with least test error rate) is a model trained on dataset 80, with 2 hidden layers 20 nodes each. The plot for the best model is presented in \@ref(fig:nnp), the actual vs. predicted confusion matrix is presented in \@ref(tab:NN_conMat), and the top 6 models are presented in \@ref(tab:NN_results).  

```{r nnp, echo=FALSE, fig.align="center", fig.cap="Best NN model (2 Hidden layers, 20 nodes each)", message=FALSE, warning=FALSE, out.width = "100%"}
knitr::include_graphics("./out/NN_best_model.png", dpi=NA)
```

\FloatBarrier
```{r NN_conMat, echo=FALSE}
df = read.csv("./out/NN_confusion_matrix.csv", header=FALSE)
knitr::kable(df, caption = "Best NN model: Actual vs. Predicted")
kable_styling(font_size = 8, latex_options="hold_position")
```

\FloatBarrier
```{r NN_results, echo=FALSE}
df = read.csv("./out/NN_results.csv", header=FALSE)
knitr::kable(df, caption = "Best NN models (arranged by test error rate")
kable_styling(font_size = 8, latex_options="hold_position")
```


\FloatBarrier

### Random Forest

Transforming (standard scaling) the variables did not improve the model accuracy either for individual feature sets or for all feature set analyses. Super-objects at segmentation scale of 40% perform better in order to create land cover maps using urban satellite images, for this specific case study with model accuracy of 79.3%. Once the coarseness scale increments, the accuracy of the model decrease in more that 10%, comparing with the broader scale of 140%. See Figure \@ref(fig:rfif).


```{r rfif, echo=FALSE, fig.align="center", fig.cap="Random Forest individual feature sets (original - transformed). Model Accuracy.", message=FALSE, warning=FALSE, out.width = "100%"}
knitr::include_graphics("./out/rf_if.png", dpi=NA)
```


\FloatBarrier

For the best Random Forest model (scale 40%) an analysis of feature importance was performed. In the Figure \@ref(fig:rffi), two types of features importance analysis is summarized, and in both, the most important variables are represented by taller bars (the black solid line represents the standard deviation). If a variable is not important for the model, the blue wide bar disappears. In the left graphic, the analysis consider the total amount of decrease in node impurity due to the splits over the predictors (Mean Decrease in Impurity - MDI), and the top five variables in importance are (a) NDVI, (b) super-object mean red, (c) mean near infrared, (d) mean green, and (e) bright. The right graphic represents a permutation variable importance analysis, with the 36% out-of-bag (OOB) samples not used in the bootstraps aggregating (bagging) sampling of random forest, and the most important variables are (a) NDVI, (b) area, (c) mean red, (d) mean near infrared, and (e) super-object near infrared standard deviation.

```{r rffi, echo=FALSE, fig.align="center", fig.cap="RF Feature Importances (MDI vs Permutation).", message=FALSE, warning=FALSE, out.width = "100%"}
knitr::include_graphics("./out/rf_fi.png", dpi=NA)
```

\FloatBarrier


Including all feature sets as a unit for random forest analysis, improved the land cover classification from 79.3% to 82.2%. 


### Nearest Neighbours

K Nearest Neighbor was applied using all features without scaling, all features with scaling, individual feature sets without scaling, and individual features sets with training. For K nearest neighbor implementation hyperparameters were tuned using the package GridSearchCV. This package allowed for a random search of best parameters using 5-fold cross validation, iterated over 1000 times. For the best model, it was found that the optimal number of neighbors was 11, Manhattan distances should be used, and all neighbors should be weighted equally. Unlike the random forest model, transforming (standard scaling) of the variables did improve the model’s accuracy for both individual feature sets and all feature set analyses (see figure \@ref(fig:knnif)). Super objects at coarseness scale of 80 provided the best results for predicting land cover types from high resolution satellite imagery, with an accuracy score of 71.8% in this project. The next best coarseness scale was 60, with just a slightly lower prediction accuracy of 71.6%. For coarseness scales above 80, the accuracy of the model decreases with each incremental increase in coarseness scale. The best KNN model classified asphalt and buildings with the highest precision, 0.83 and 0.82 respectively, and classified cars and soil with the lowest precision, 0.31 and 0.46 respectively. In summary, the KNN model with the best performance was the one with image segmentation at coarseness scale 80, which provided an accuracy of 71.8%. 

#### Individual Feature Sets

```{r knnif, echo=FALSE, fig.align="center", fig.cap="KNN individual feature sets (original - transformed). Model Accuracy.", message=FALSE, warning=FALSE, out.width = "100%"}
knitr::include_graphics("./out/knn_if.png", dpi=NA)
```

\FloatBarrier


#### All Feature Sets



```{r knnaf, echo=FALSE, fig.align="center", fig.cap="RF all features (original - transformed). Model Accuracy.", message=FALSE, warning=FALSE, out.width = "50%"}
knitr::include_graphics("./out/knn_af.png", dpi=NA)
```

\FloatBarrier


# Disscussion and Conclusions


The Table \@ref(tab:ball), shows the best model for all methods, indicating if the data was transformed (standard scaling) and the image segmentation scale of the corresponding feature set.

accuracy_best_all_methods.csv

```{r ball, echo=FALSE}
df = read.csv("./out/accuracy_best_all_methods.csv", header=T)


df$Accuracy <- ifelse(
  df$Accuracy ==  max(df$Accuracy),
  paste("\\color{red}{",df$Accuracy, "}"), #cell_spec(df$Accuracy, color = "red", bold = T),
  df$Accuracy # cell_spec(df$Accuracy, color = "black", italic = F)
)

df$Accuracy.1 <- ifelse(
  df$Accuracy.1 ==  max(df$Accuracy.1),
  paste("\\color{red}{",df$Accuracy.1, "}"), #cell_spec(df$Accuracy.1, color = "red", bold = T),
  df$Accuracy.1 #
)


knitr::kable(df, caption = "Best Model. All Machine Learning Methods", 
             col.names = c("Method", "Data", "Segmentation Scale", 
                           "Accuracy", "Accuracy"), escape = F) %>%
      #column_spec(1,width = "2in") %>%
      #column_spec(2,width = "3.8in") %>%
kable_styling(font_size = 8, latex_options="hold_position") %>%
add_header_above(c(" " = 1, "Individual Feature Sets" = 3, "All Feature Sets" = 1))
```

\FloatBarrier

As was mentioned in the project proposal, there are highly correlated variables across all feature sets, because each variable represents the same feature for the same super-object, but is extracted at a different image segmentation scale. Nonetheless, some of the main advantages of random forest are (a) decreasing auto-correlation in the trees by using only a random selection of variables, and (b) basing the prediction on the most important variables, therefore, this type of analysis with repeated correlated variables at multiples scales, when considered as a unity, is ideal for random forest classifier because it itself uses the most important inputs and selects the most representative elements to increase the accuracy of the final prediction without the need for an exhaustive exploratory analysis prior. Random forest was the best predictor in this study, with all variables, using both individual feature sets (79.3% of accuracy) or all together (82.3% of accuracy). 


The Figure \@ref(fig:bm), shows the classification report for the best model (random forest at scale 40%). The best performance is achieved in classes *asphalt* and *building*, and the worse results are for classes *soil* and *tree*.


```{r bm, echo=FALSE, fig.align="center", fig.cap="Classification Report - Best Model. RF Scale 40. Feature Set 2 (not transformed)", message=FALSE, warning=FALSE, out.width = "60%"}
knitr::include_graphics("./out/rf_bm.png", dpi=NA)
```
\FloatBarrier






# References

