# fit a neural network for the full data set
fit <- neuralnet(class~. , data = trainingList[[i]], hidden = hiddenList[[j]], algorithm = "rprop+", act.fct = 'logistic',  linear.output = FALSE)
#stop timer
timer <- toc()
#predicting values of testing set using fit model
pred <- predict(fit, testingList[[i]])
#confusion matrix, actual vs. predicted
cMatrix <- table(testingList[[i]]$class, apply(pred, 1, which.max))
#name for the configuration
config <- paste(hiddenList[j])
#calculating test error rate
testError <- 1- sum(diag(cMatrix))/length(testingList[[i]]$class)
# combining data set name, hidden configuration, error rate, and compute time
outcome <- c(names(trainingList[i]), config, testError, (timer$toc-timer$tic))
# save the best fit
if(outcome[3] < min(results$Test.Error.Rate)){ bestFit <- c(fit, outcome)}
#add outcome to the results dataframe
results <- rbind(results, outcome)
#partial data set
#start timer
tic()
# fit a neural network for the full data set
fit <- neuralnet(class~. , data = parTrainingList[[i]], hidden = hiddenList[[j]], algorithm = "rprop+", act.fct = 'logistic',  linear.output = FALSE)
#stop timer
timer <- toc()
#predicting values of testing set using fit model
pred <- predict(fit, parTestingList[[i]])
#confusion matrix, actual vs. predicted
cMatrix <- table(parTestingList[[i]]$class, apply(pred, 1, which.max))
#name for the configuration
config <- paste(hiddenList[j])
#calculating test error rate
testError <- 1- sum(diag(cMatrix))/length(parTestingList[[i]]$class)
# combining data set name, hidden configuration, error rate, and compute time
outcome <- c(names(parTrainingList[i]), config, testError, (timer$toc-timer$tic))
# save the best fit
if(outcome[3] < min(results$Test.Error.Rate)){ bestFit <- c(fit, outcome)}
#add outcome to the results dataframe
results <- rbind(results, outcome)
}
}
View(bestFit)
knitr::opts_chunk$set(echo = TRUE)
library(neuralnet)
library(tictoc)
#This routine only loads the data from original .csv files, and separate them into each coarseness level, no need to write the code here since its function is trivial
source('preprocessor.r', local = TRUE)
#* This section includes the fitting and evaluation of neural networks
#*
# declare output dataframe
results <- data.frame("Data Set" = 0, "configurations" = 0, "Test Error Rate" = 1, "Time" = 0)
# declare hidden list configurations
hiddenList <- list()
hiddenList[[1]] <- 10; hiddenList[[2]] <- c(10,10); hiddenList[[3]] <- c(10,10,10)
hiddenList[[4]] <- 20; hiddenList[[5]] <- c(20,20); hiddenList[[6]] <- c(20,20,20)
#loop through length of lists
for (i in 1:length(trainingList)){
#loop through hidden list configurations
for (j in 1:length(hiddenList) ){
#full data set
#start timer
tic()
# fit a neural network for the full data set
fit <- neuralnet(class~. , data = trainingList[[i]], hidden = hiddenList[[j]], algorithm = "rprop+", act.fct = 'logistic',  linear.output = FALSE)
#stop timer
timer <- toc()
#predicting values of testing set using fit model
pred <- predict(fit, testingList[[i]])
#confusion matrix, actual vs. predicted
cMatrix <- table(testingList[[i]]$class, apply(pred, 1, which.max))
#name for the configuration
config <- paste(hiddenList[j])
#calculating test error rate
testError <- 1- sum(diag(cMatrix))/length(testingList[[i]]$class)
# combining data set name, hidden configuration, error rate, and compute time
outcome <- c(names(trainingList[i]), config, testError, (timer$toc-timer$tic))
# save the best fit
if(outcome[3] < min(results$Test.Error.Rate)){ bestFit <- c(fit, outcome)}
#add outcome to the results dataframe
results <- rbind(results, outcome)
#partial data set
#start timer
tic()
# fit a neural network for the full data set
fit <- neuralnet(class~. , data = parTrainingList[[i]], hidden = hiddenList[[j]], algorithm = "rprop+", act.fct = 'logistic',  linear.output = FALSE)
#stop timer
timer <- toc()
#predicting values of testing set using fit model
pred <- predict(fit, parTestingList[[i]])
#confusion matrix, actual vs. predicted
cMatrix <- table(parTestingList[[i]]$class, apply(pred, 1, which.max))
#name for the configuration
config <- paste(hiddenList[j])
#calculating test error rate
testError <- 1- sum(diag(cMatrix))/length(parTestingList[[i]]$class)
# combining data set name, hidden configuration, error rate, and compute time
outcome <- c(names(parTrainingList[i]), config, testError, (timer$toc-timer$tic))
# save the best fit
if(outcome[3] < min(results$Test.Error.Rate)){ bestFit <- c(fit, outcome)}
#add outcome to the results dataframe
results <- rbind(results, outcome)
}
}
# cleanup
results <- results[-1,]
rm(fit, pred, timer, cMatrix, i, j, outcome, testError, config)
View(results)
knitr::opts_chunk$set(echo = TRUE)
library(neuralnet)
library(tictoc)
#This routine only loads the data from original .csv files, and separate them into each coarseness level, no need to write the code here since its function is trivial
source('preprocessor.r', local = TRUE)
#* This section includes the fitting and evaluation of neural networks
#*
set.seed(6500)
# declare output dataframe
results <- data.frame("Data Set" = 0, "configurations" = 0, "Test Error Rate" = 1, "Time" = 0)
# declare hidden list configurations
hiddenList <- list()
hiddenList[[1]] <- 10; hiddenList[[2]] <- c(10,10); hiddenList[[3]] <- c(10,10,10)
hiddenList[[4]] <- 20; hiddenList[[5]] <- c(20,20); hiddenList[[6]] <- c(20,20,20)
#loop through length of lists
for (i in 1:length(trainingList)){
#loop through hidden list configurations
for (j in 1:length(hiddenList) ){
#full data set
#start timer
tic()
# fit a neural network for the full data set
fit <- neuralnet(class~. , data = trainingList[[i]], hidden = hiddenList[[j]], algorithm = "rprop+", act.fct = 'logistic',  linear.output = FALSE)
#stop timer
timer <- toc()
#predicting values of testing set using fit model
pred <- predict(fit, testingList[[i]])
#confusion matrix, actual vs. predicted
cMatrix <- table(testingList[[i]]$class, apply(pred, 1, which.max))
#name for the configuration
config <- paste(hiddenList[j])
#calculating test error rate
testError <- 1- sum(diag(cMatrix))/length(testingList[[i]]$class)
# combining data set name, hidden configuration, error rate, and compute time
outcome <- c(names(trainingList[i]), config, testError, (timer$toc-timer$tic))
# save the best fit
if(outcome[3] < min(results$Test.Error.Rate)){ bestFit <- c(fit, outcome)}
#add outcome to the results dataframe
results <- rbind(results, outcome)
#partial data set
#start timer
tic()
# fit a neural network for the full data set
fit <- neuralnet(class~. , data = parTrainingList[[i]], hidden = hiddenList[[j]], algorithm = "rprop+", act.fct = 'logistic',  linear.output = FALSE)
#stop timer
timer <- toc()
#predicting values of testing set using fit model
pred <- predict(fit, parTestingList[[i]])
#confusion matrix, actual vs. predicted
cMatrix <- table(parTestingList[[i]]$class, apply(pred, 1, which.max))
#name for the configuration
config <- paste(hiddenList[j])
#calculating test error rate
testError <- 1- sum(diag(cMatrix))/length(parTestingList[[i]]$class)
# combining data set name, hidden configuration, error rate, and compute time
outcome <- c(names(parTrainingList[i]), config, testError, (timer$toc-timer$tic))
# save the best fit
if(outcome[3] < min(results$Test.Error.Rate)){ bestFit <- c(fit, outcome)}
#add outcome to the results dataframe
results <- rbind(results, outcome)
}
}
# cleanup
results <- results[-1,]
rm(fit, pred, timer, cMatrix, i, j, outcome, testError, config)
View(results)
View(bestFit)
plot(bestFit)
knitr::opts_chunk$set(echo = TRUE)
library(neuralnet)
library(tictoc)
#This routine only loads the data from original .csv files, and separate them into each coarseness level, no need to write the code here since its function is trivial
source('preprocessor.r', local = TRUE)
#* This section includes the fitting and evaluation of neural networks
#*
set.seed(6500)
# declare output dataframe
results <- data.frame("Data Set" = 0, "configurations" = 0, "Test Error Rate" = 1, "Time" = 0)
# declare hidden list configurations
hiddenList <- list()
hiddenList[[1]] <- 10; hiddenList[[2]] <- c(10,10); hiddenList[[3]] <- c(10,10,10)
hiddenList[[4]] <- 20; hiddenList[[5]] <- c(20,20); hiddenList[[6]] <- c(20,20,20)
#declare best fit list
bestFit <- list()
#loop through length of lists
for (i in 1:length(trainingList)){
#loop through hidden list configurations
for (j in 1:length(hiddenList) ){
#full data set
#start timer
tic()
# fit a neural network for the full data set
fit <- neuralnet(class~. , data = trainingList[[i]], hidden = hiddenList[[j]], algorithm = "rprop+", act.fct = 'logistic',  linear.output = FALSE)
#stop timer
timer <- toc(quiet = TRUE)
#predicting values of testing set using fit model
pred <- predict(fit, testingList[[i]])
#confusion matrix, actual vs. predicted
cMatrix <- table(testingList[[i]]$class, apply(pred, 1, which.max))
#name for the configuration
config <- paste(hiddenList[j])
#calculating test error rate
testError <- 1- sum(diag(cMatrix))/length(testingList[[i]]$class)
# combining data set name, hidden configuration, error rate, and compute time
outcome <- c(names(trainingList[i]), config, testError, (timer$toc-timer$tic))
# save the best fit
if(outcome[3] < min(results$Test.Error.Rate)){ bestFit[[1]] <- fit; bestFit[[2]] <- outcome }
#add outcome to the results dataframe
results <- rbind(results, outcome)
#partial data set
#start timer
tic()
# fit a neural network for the full data set
fit <- neuralnet(class~. , data = parTrainingList[[i]], hidden = hiddenList[[j]], algorithm = "rprop+", act.fct = 'logistic',  linear.output = FALSE)
#stop timer
timer <- toc(quiet = TRUE)
#predicting values of testing set using fit model
pred <- predict(fit, parTestingList[[i]])
#confusion matrix, actual vs. predicted
cMatrix <- table(parTestingList[[i]]$class, apply(pred, 1, which.max))
#name for the configuration
config <- paste(hiddenList[j])
#calculating test error rate
testError <- 1- sum(diag(cMatrix))/length(parTestingList[[i]]$class)
# combining data set name, hidden configuration, error rate, and compute time
outcome <- c(names(parTrainingList[i]), config, testError, (timer$toc-timer$tic))
# save the best fit
if(outcome[3] < min(results$Test.Error.Rate)){ bestFit <- c(fit, outcome)}
#add outcome to the results dataframe
results <- rbind(results, outcome)
}
}
# cleanup
results <- results[-1,]
rm(fit, pred, timer, cMatrix, i, j, outcome, testError, config)
plot(bestFit[[1]])
head(results[order(Test.Error.Rate, Time)])
head(results[order(Test Error Rate, Time)])
head(results[order(Test Error Rate, Time)],)
head(results[order(Test.Error.Rate, Time)],)
head(results[order(results$Test.Error.Rate, results$Time),])
plot(bestFit[[1]])
head(results[order(results$Test.Error.Rate, results$Time),])
gwplot(bestFit[[1]])
gwplot(bestFit[[1]], selected.response = class)
gwplot(bestFit[[1]], selected.covariate = class)
gwplot(bestFit[[1]], selected.response = 'car')
plot(bestFit[[1]], rep="best")
knitr::opts_chunk$set(echo = TRUE)
library(neuralnet)
library(tictoc)
library(datasets)
gwplot(bestFit[[1]])
infert
gwplot(bestFit[[1]], selected.response = "car")
gwplot(bestFit[[1]], selected.response = "class")
gwplot(bestFit[[1]], selected.covariate = 'Area')
gwplot(fit, selected.covariate = 'Area')
bestFit[[1]]
data(infert, package="datasets")
print(net.infert <- neuralnet(case~parity+induced+spontaneous, infert,
err.fct="ce", linear.output=FALSE, likelihood=TRUE))
gwplot(net.infert, selected.covariate="parity")
gwplot(net.infert, selected.covariate="induced")
gwplot(net.infert, selected.covariate="spontaneous")
knitr::opts_chunk$set(echo = TRUE)
library(neuralnet)
library(tictoc)
library(datasets)
knitr::opts_chunk$set(echo = TRUE)
library(neuralnet)
library(tictoc)
#This routine only loads the data from original .csv files, and separate them into each coarseness level, no need to write the code here since its function is trivial
source('preprocessor.r', local = TRUE)
#* This section includes the fitting and evaluation of neural networks
#*
set.seed(6500)
# declare output dataframe
results <- data.frame("Data Set" = 0, "configurations" = 0, "Test Error Rate" = 1, "Time" = 0)
# declare hidden list configurations
hiddenList <- list()
hiddenList[[1]] <- 10; hiddenList[[2]] <- c(10,10); hiddenList[[3]] <- c(10,10,10)
hiddenList[[4]] <- 20; hiddenList[[5]] <- c(20,20); hiddenList[[6]] <- c(20,20,20)
#declare best fit list
bestFit <- list()
#loop through length of lists
for (i in 1:length(trainingList)){
#loop through hidden list configurations
for (j in 1:length(hiddenList) ){
#full data set
#start timer
tic()
# fit a neural network for the full data set
fit <- neuralnet(class~. , data = trainingList[[i]], hidden = hiddenList[[j]], algorithm = "rprop+", act.fct = 'logistic',  linear.output = FALSE, likelihood = TRUE)
#stop timer
timer <- toc(quiet = TRUE)
#predicting values of testing set using fit model
pred <- predict(fit, testingList[[i]])
#confusion matrix, actual vs. predicted
cMatrix <- table(testingList[[i]]$class, apply(pred, 1, which.max))
#name for the configuration
config <- paste(hiddenList[j])
#calculating test error rate
testError <- 1- sum(diag(cMatrix))/length(testingList[[i]]$class)
# combining data set name, hidden configuration, error rate, and compute time
outcome <- c(names(trainingList[i]), config, testError, (timer$toc-timer$tic))
# save the best fit
if(outcome[3] < min(results$Test.Error.Rate)){ bestFit[[1]] <- fit; bestFit[[2]] <- outcome }
#add outcome to the results dataframe
results <- rbind(results, outcome)
#partial data set
#start timer
tic()
# fit a neural network for the full data set
fit <- neuralnet(class~. , data = parTrainingList[[i]], hidden = hiddenList[[j]], algorithm = "rprop+", act.fct = 'logistic',  linear.output = FALSE, likelihood = TRUE)
#stop timer
timer <- toc(quiet = TRUE)
#predicting values of testing set using fit model
pred <- predict(fit, parTestingList[[i]])
#confusion matrix, actual vs. predicted
cMatrix <- table(parTestingList[[i]]$class, apply(pred, 1, which.max))
#name for the configuration
config <- paste(hiddenList[j])
#calculating test error rate
testError <- 1- sum(diag(cMatrix))/length(parTestingList[[i]]$class)
# combining data set name, hidden configuration, error rate, and compute time
outcome <- c(names(parTrainingList[i]), config, testError, (timer$toc-timer$tic))
# save the best fit
if(outcome[3] < min(results$Test.Error.Rate)){ bestFit <- c(fit, outcome)}
#add outcome to the results dataframe
results <- rbind(results, outcome)
}
}
# cleanup
results <- results[-1,]
rm(fit, pred, timer, cMatrix, i, j, outcome, testError, config)
bestFit[[1]]$err.fct()
bestFit[[1]]$result.matrix
View(bestFit)
bestFit[["result.matrix"]]
fit <- neuralnet(class~. , data = trainingList[[1]], hidden = hiddenList[[1]], algorithm = "rprop+", act.fct = 'logistic',  linear.output = FALSE, likelihood = TRUE)
fit$result.matrix[1]
fit$result.matrix
fit$result.matrix[3]
#This routine only loads the data from original .csv files, and separate them into each coarseness level, no need to write the code here since its function is trivial
source('preprocessor.r', local = TRUE)
#* This section includes the fitting and evaluation of neural networks
#*
set.seed(6500)
# declare output dataframe
results <- data.frame("Data Set" = 0, "configurations" = 0, "Test Error Rate" = 1,
"Time" = 0, "AIC" = 0, "BIC" = 0, "Steps" = 0)
# declare hidden list configurations
hiddenList <- list()
hiddenList[[1]] <- 10; hiddenList[[2]] <- c(10,10); hiddenList[[3]] <- c(10,10,10)
hiddenList[[4]] <- 20; hiddenList[[5]] <- c(20,20); hiddenList[[6]] <- c(20,20,20)
#declare best fit list
bestFit <- list()
#loop through length of lists
for (i in 1:length(trainingList)){
#loop through hidden list configurations
for (j in 1:length(hiddenList) ){
#full data set
#start timer
tic()
# fit a neural network for the full data set
fit <- neuralnet(class~. , data = trainingList[[i]], hidden = hiddenList[[j]], algorithm = "rprop+", act.fct = 'logistic',  linear.output = FALSE, likelihood = TRUE)
#stop timer
timer <- toc(quiet = TRUE)
#predicting values of testing set using fit model
pred <- predict(fit, testingList[[i]])
#confusion matrix, actual vs. predicted
cMatrix <- table(testingList[[i]]$class, apply(pred, 1, which.max))
#name for the configuration
config <- paste(hiddenList[j])
#calculating test error rate
testError <- 1- sum(diag(cMatrix))/length(testingList[[i]]$class)
# combining data set name, hidden configuration, error rate, and compute time
outcome <- c(names(trainingList[i]), config, testError, (timer$toc-timer$tic), fit$result.matrix[4], fit$result.matrix[5], fit$result.matrix[3])
# save the best fit
if(outcome[3] < min(results$Test.Error.Rate)){ bestFit[[1]] <- fit; bestFit[[2]] <- outcome }
#add outcome to the results dataframe
results <- rbind(results, outcome)
#partial data set
#start timer
tic()
# fit a neural network for the full data set
fit <- neuralnet(class~. , data = parTrainingList[[i]], hidden = hiddenList[[j]], algorithm = "rprop+", act.fct = 'logistic',  linear.output = FALSE, likelihood = TRUE)
#stop timer
timer <- toc(quiet = TRUE)
#predicting values of testing set using fit model
pred <- predict(fit, parTestingList[[i]])
#confusion matrix, actual vs. predicted
cMatrix <- table(parTestingList[[i]]$class, apply(pred, 1, which.max))
#name for the configuration
config <- paste(hiddenList[j])
#calculating test error rate
testError <- 1- sum(diag(cMatrix))/length(parTestingList[[i]]$class)
# combining data set name, hidden configuration, error rate, and compute time
outcome <- c(names(trainingList[i]), config, testError, (timer$toc-timer$tic), fit$result.matrix[4], fit$result.matrix[5], fit$result.matrix[3])
# save the best fit
if(outcome[3] < min(results$Test.Error.Rate)){ bestFit <- c(fit, outcome)}
#add outcome to the results dataframe
results <- rbind(results, outcome)
}
}
# cleanup
results <- results[-1,]
rm(fit, pred, timer, cMatrix, i, j, outcome, testError, config)
View(results)
View(results)
plot(bestFit[[1]])
head(results[order(results$Test.Error.Rate,])
head(results[order(results$Test.Error.Rate,)])
plot(bestFit[[1]])
head(results[order(results$Test.Error.Rate,)])
head(results[order(results$Test.Error.Rate, results$Time),])
head(results[order(results$Test.Error.Rate),])
plot(bestFit[[1]])
#top 6 results ordered by test error rate
head(results[order(results$Test.Error.Rate),])
#top 6 results ordered by test error rate
head(results[order(results$AIC),])
#top 6 results ordered by test error rate
head(results[order(results$BIC),])
range(results$Test.Error.Rate)
range(results$Time)
range(results$AIC)
knitr::opts_chunk$set(echo = TRUE)
library(neuralnet)
library(tictoc)
#This routine only loads the data from original .csv files, and separate them into each coarseness level, no need to write the code here since its function is trivial
source('preprocessor.r', local = TRUE)
#* This section includes the fitting and evaluation of neural networks
#*
set.seed(6500)
# declare output dataframe
results <- data.frame("Data Set" = 0, "configurations" = 0, "Test Error Rate" = 1,
"Time" = 0, "AIC" = 0, "BIC" = 0, "Steps" = 0)
# declare hidden list configurations
hiddenList <- list()
hiddenList[[1]] <- 10; hiddenList[[2]] <- c(10,10); hiddenList[[3]] <- c(10,10,10)
hiddenList[[4]] <- 20; hiddenList[[5]] <- c(20,20); hiddenList[[6]] <- c(20,20,20)
#declare best fit list
bestFit <- list()
#loop through length of lists
for (i in 1:length(trainingList)){
#loop through hidden list configurations
for (j in 1:length(hiddenList) ){
#full data set
#start timer
tic()
# fit a neural network for the full data set
fit <- neuralnet(class~. , data = trainingList[[i]], hidden = hiddenList[[j]], algorithm = "rprop+", act.fct = 'logistic',  linear.output = FALSE, likelihood = TRUE)
#stop timer
timer <- toc(quiet = TRUE)
#predicting values of testing set using fit model
pred <- predict(fit, testingList[[i]])
#confusion matrix, actual vs. predicted
cMatrix <- table(testingList[[i]]$class, apply(pred, 1, which.max))
#name for the configuration
config <- paste(hiddenList[j])
#calculating test error rate
testError <- 1- sum(diag(cMatrix))/length(testingList[[i]]$class)
# combining data set name, hidden configuration, error rate, and compute time
outcome <- c(names(trainingList[i]), config, testError, (timer$toc-timer$tic), fit$result.matrix[4], fit$result.matrix[5], fit$result.matrix[3])
# save the best fit
if(outcome[3] < min(results$Test.Error.Rate)){ bestFit[[1]] <- fit; bestFit[[2]] <- outcome }
#add outcome to the results dataframe
results <- rbind(results, outcome)
#partial data set
#start timer
tic()
# fit a neural network for the full data set
fit <- neuralnet(class~. , data = parTrainingList[[i]], hidden = hiddenList[[j]], algorithm = "rprop+", act.fct = 'logistic',  linear.output = FALSE, likelihood = TRUE)
#stop timer
timer <- toc(quiet = TRUE)
#predicting values of testing set using fit model
pred <- predict(fit, parTestingList[[i]])
#confusion matrix, actual vs. predicted
cMatrix <- table(parTestingList[[i]]$class, apply(pred, 1, which.max))
#name for the configuration
config <- paste(hiddenList[j])
#calculating test error rate
testError <- 1- sum(diag(cMatrix))/length(parTestingList[[i]]$class)
# combining data set name, hidden configuration, error rate, and compute time
outcome <- c(names(parTrainingList[i]), config, testError, (timer$toc-timer$tic), fit$result.matrix[4], fit$result.matrix[5], fit$result.matrix[3])
# save the best fit
if(outcome[3] < min(results$Test.Error.Rate)){ bestFit <- c(fit, outcome)}
#add outcome to the results dataframe
results <- rbind(results, outcome)
}
}
# cleanup
results <- results[-1,]
rm(fit, pred, timer, cMatrix, i, j, outcome, testError, config)
plot(bestFit[[1]])
#top 6 results ordered by test error rate
head(results[order(results$Test.Error.Rate),])
#top 6 results ordered by test error rate
head(results[order(results$AIC),])
#top 6 results ordered by test error rate
head(results[order(results$BIC),])
range(results$AIC)
range(results$BIC)
